# CM3588 + AX650N — Оптимизация PCIe

**[English](README.md)** | **[中文](README.zh.md)**

> Ускорение LLM inference на +50% для [M5Stack Module LLM (AI-8850)](https://docs.m5stack.com/en/guide/ai_accelerator/llm-8850/m5_llm_8850_software_install) на [FriendlyElec CM3588 NAS](https://wiki.friendlyelec.com/wiki/index.php/CM3588).

## Проблема

NPU AX650N (24 TOPS INT8), подключённый через M.2 на CM3588 NAS, выдаёт только **7-7.5 tok/s** при LLM inference (Qwen3-0.6B) вместо ожидаемых 12-13 tok/s. Причины:

1. **Аппаратное ограничение PCIe Gen2 x1** — CM3588 разводит только 1 линию к M.2 слоту (устройство поддерживает x2)
2. **IRQ на маленьком ядре** — все прерывания обрабатываются медленным Cortex-A55 @ 1.8 ГГц
3. **Динамическое масштабирование частоты** — CPU снижает частоту между вызовами inference

## Решение

Этот toolkit применяет две оптимизации, дающие **+50% прирост** (Qwen3-0.6B):

| | До | После |
|--|-----|-------|
| Скорость декода | 7.1-7.5 tok/s | **10-12 tok/s** |
| TTFT (prefill) | 488-578 мс | **391 мс** |
| Стабильность | Высокий разброс | Стабильно |

## Быстрый старт

```bash
git clone https://github.com/MasterVVK/cm3588-ax650n-pcie-tuning.git
cd cm3588-ax650n-pcie-tuning
sudo ./install.sh
```

Оптимизация сохраняется после перезагрузок через systemd service.

## Что делает

1. **Переносит IRQ AX650N на большое ядро** — с Cortex-A55 (CPU0) на Cortex-A76 (CPU4)
2. **Устанавливает performance governor** — фиксирует частоту больших ядер на 2.3 ГГц
3. **Автоопределение** PCIe адреса AX650N и топологии CPU
4. **Сохраняется после ребута** через systemd service

## Диагностика

```bash
sudo ax650n-diagnose.sh
```

Показывает: PCIe топологию, скорость/ширину линка, MaxPayload, привязку IRQ, governor CPU и рекомендации.

## Результаты бенчмарков

### LLM Inference

Скорость декода (tok/s) через AXCL runtime на CM3588 PCIe Gen2 x1:

| Модель | Квант. | По умолч. | Оптимиз. | Ускорение | Native (офиц.) |
|--------|--------|----------:|---------:|----------:|---------------:|
| Qwen3-0.6B | W8A16 | 7.1-7.5 | **10-12** | +50% | 19-20 |
| Qwen3-1.7B | W8A16 | 5.1-5.3 | **7.8-8.0** | +50% | 7.42 |
| Qwen3-4B | W8A16 | 2.6-2.8 | **3.7** | +37% | — |
| Qwen2.5-7B | W4A16 | 3.7 | **4.4** | +19% | 4.8 |

TTFT (время до первого токена):

| Модель | По умолч. | Оптимиз. | Ускорение |
|--------|----------:|---------:|----------:|
| Qwen3-0.6B | 488-578 мс | **391 мс** | +25% |
| Qwen3-1.7B | 541 мс | **447 мс** | +21% |
| Qwen3-4B | 1216 мс | **1110 мс** | +10% |

Qwen3-1.7B с оптимизацией достигает **~108% от официального native** (7.9 vs 7.42) — вероятно, вариация измерений, но PCIe overhead фактически устранён для compute-bound моделей. Qwen2.5-7B: **92% от native** (4.4 vs 4.8).

### Vision модели (NPU inference, 640x640)

| Модель | По умолч. (мс) | Оптимизировано (мс) | Ускорение | FPS |
|--------|----------:|------------:|--------:|----:|
| YOLO11s | 3.99 | **3.55** | +12% | 282 |
| YOLOv8s | 4.21 | **3.89** | +8% | 257 |
| YOLO11s-Seg | 5.27 | **4.60** | +13% | 217 |
| YOLOv8s-Seg | 5.26 | **5.11** | +3% | 196 |
| YOLOv5s | 6.92 | **6.59** | +5% | 152 |
| YOLO26m | 9.47 | **9.04** | +5% | 111 |
| YOLOv8s-Pose | 11.81 | **11.26** | +5% | 89 |
| Depth-Anything-V2-S | 34.00 | **33.44** | +2% | 30 |

Ключевой эффект для vision: **2-13% быстрее + стабильность в 2-3 раза выше** (критично для realtime pipeline).

### Классификация (NPU inference, 224x224)

| Модель | По умолч. (мс) | Оптимизировано (мс) | Ускорение | FPS |
|--------|----------:|------------:|--------:|----:|
| MobileNetV2 | 0.983 | **0.657** | +50% | 1523 |
| SqueezeNet1.1 | 0.786 | **0.768** | +2% | 1302 |
| ResNet18 | 1.963 | **1.435** | +37% | 697 |
| ResNet50 | 3.613 | **3.355** | +8% | 298 |

### OCR — PPOCR_v5 (Детекция + Распознавание текста)

| Модель | Задача | По умолч. (мс) | Оптимизировано (мс) | Ускорение |
|--------|--------|----------:|------------:|--------:|
| det_npu1 | Детекция текста | 29.38 | **28.98** | +1% |
| cls_npu1 | Направление текста | 0.759 | **0.445** | +71% |
| rec_npu1 | Распознавание текста | 3.958 | **3.681** | +8% |

### Распознавание лиц — Insightface

| Модель | Задача | По умолч. (мс) | Оптимизировано (мс) | Ускорение | FPS |
|--------|--------|----------:|------------:|--------:|----:|
| det_10g | Детекция | 7.36 | **6.86** | +7% | 146 |
| genderage | Пол/Возраст | 0.479 | **0.357** | +34% | 2801 |
| w600k_r50 | Эмбеддинги | 4.27 | **3.72** | +15% | 269 |

### Super-Resolution, Сегментация, Zero-Shot, Речь

| Модель | Задача | По умолч. (мс) | Оптимизировано (мс) | Ускорение |
|--------|--------|----------:|------------:|--------:|
| Real-ESRGAN x4 | 64→256 апскейл | 15.85 | **15.66** | +1% |
| Real-ESRGAN x4 | 256→1024 апскейл | 476.2 | **475.4** | +0.2% |
| MobileSAM encoder | Сегментация | 51.52 | **50.92** | +1% |
| MobileSAM decoder | Сегментация | 10.59 | **10.35** | +2% |
| SigLIP2 vision | Zero-shot изобр. | 11.48 | **11.37** | +1% |
| SigLIP2 text | Zero-shot текст | 5.00 | **4.57** | +10% |
| RT-DETR | Детекция | 9.52 | **9.35** | +2% |
| YOLO-World | Детекция | 9.71 | **9.25** | +5% |
| Whisper-tiny enc | Речь в текст | 21.27 | **21.13** | +1% |
| Whisper-tiny dec | Речь в текст | 4.05 | **3.93** | +3% |

### TTS — CosyVoice3 (русский текст на NPU)

| Метрика | По умолч. | Оптимизировано | Ускорение |
|---------|----------:|---------:|--------:|
| TTFT | 125 мс | **108 мс** | +16% |
| LLM Decode | 13.9 tok/s | **16.3 tok/s** | +17% |
| RTF | 2.0-3.7x | **1.7-1.9x** | |

### Паттерн эффекта оптимизации

Ускорение обратно пропорционально времени inference — быстрые модели получают больший выигрыш:

| Время inference | Пример | Ускорение |
|:-:|:-:|:-:|
| ~0.3 мс | Insightface genderage | **+34%** |
| < 0.5 мс | OCR классификатор | **+71%** |
| ~0.7 мс | MobileNetV2 | **+50%** |
| ~1.4 мс | ResNet18 | **+37%** |
| ~3.7 мс | Insightface w600k_r50 | +15% |
| ~3.5 мс | ResNet50 | +8% |
| ~7 мс | YOLOv5s | +5% |
| ~29 мс | OCR детектор | +1% |
| ~475 мс | Real-ESRGAN 256→1024 | +0.2% |

Это объясняется тем, что задержка PCIe round-trip (~0.3 мс) занимает большую долю общего времени у быстрых моделей.

**30+ моделей протестировано** в 10 категориях: LLM (4 размера моделей, от 0.6B до 7B), детекция, сегментация, классификация, OCR, распознавание лиц, super-resolution, zero-shot, распознавание речи и TTS.

Подробнее: [результаты бенчмарков](docs/benchmark-results.md) и [анализ PCIe архитектуры](docs/pcie-analysis.md).

## Требования

- FriendlyElec CM3588 NAS (RK3588)
- AX650N M.2 модуль ([M5Stack Module LLM](https://docs.m5stack.com/en/guide/ai_accelerator/llm-8850/m5_llm_8850_software_install) или аналог)
- Установленный драйвер AXCL ([ax-llm](https://github.com/AXERA-TECH/ax-llm))
- Root-доступ

## Удаление

```bash
sudo ./uninstall.sh
```

## Ссылки

- [CM3588 Wiki](https://wiki.friendlyelec.com/wiki/index.php/CM3588) — документация FriendlyElec CM3588
- [M5Stack Module LLM](https://docs.m5stack.com/en/guide/ai_accelerator/llm-8850/m5_llm_8850_software_install) — документация M5Stack AI-8850 / AX650N
- [ax-llm](https://github.com/AXERA-TECH/ax-llm) — движок LLM inference от Axera
- [AXCL](https://github.com/AXERA-TECH/axcl) — Axera PCIe host SDK

## Лицензия

[MIT](LICENSE)
